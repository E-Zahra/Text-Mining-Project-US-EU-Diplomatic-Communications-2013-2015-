{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertopic\n",
      "  Downloading bertopic-0.17.4-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting umap-learn\n",
      "  Downloading umap_learn-0.5.9.post2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting hdbscan\n",
      "  Downloading hdbscan-0.8.41-cp311-cp311-macosx_10_9_universal2.whl.metadata (15 kB)\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from bertopic) (2.2.5)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from bertopic) (2.2.3)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from bertopic) (6.5.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from bertopic) (1.7.2)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /Users/majid/.local/lib/python3.11/site-packages (from bertopic) (4.67.1)\n",
      "Collecting llvmlite>0.36.0 (from bertopic)\n",
      "  Downloading llvmlite-0.46.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from sentence-transformers) (1.16.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/majid/.local/lib/python3.11/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Collecting numba>=0.51.2 (from umap-learn)\n",
      "  Downloading numba-0.63.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.9 kB)\n",
      "Collecting pynndescent>=0.5 (from umap-learn)\n",
      "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: joblib>=1.0 in /Users/majid/.local/lib/python3.11/site-packages (from hdbscan) (1.5.2)\n",
      "Collecting smart_open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from pandas>=1.1.5->bertopic) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from plotly>=4.7.0->bertopic) (2.14.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from scikit-learn>=1.0->bertopic) (3.6.0)\n",
      "Collecting wrapt (from smart_open>=1.8.1->gensim)\n",
      "  Downloading wrapt-2.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.1.31)\n",
      "Downloading bertopic-0.17.4-py3-none-any.whl (154 kB)\n",
      "Downloading sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
      "Downloading umap_learn-0.5.9.post2-py3-none-any.whl (90 kB)\n",
      "Downloading hdbscan-0.8.41-cp311-cp311-macosx_10_9_universal2.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gensim-4.4.0-cp311-cp311-macosx_11_0_arm64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m  \u001b[33m0:00:11\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.46.0-cp311-cp311-macosx_11_0_arm64.whl (37.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.2/37.2 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m  \u001b[33m0:00:10\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.63.1-cp311-cp311-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "Downloading smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Downloading wrapt-2.0.1-cp311-cp311-macosx_11_0_arm64.whl (61 kB)\n",
      "Installing collected packages: wrapt, llvmlite, smart_open, numba, pynndescent, hdbscan, gensim, umap-learn, sentence-transformers, bertopic\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [bertopic]/10\u001b[0m [bertopic]transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed bertopic-0.17.4 gensim-4.4.0 hdbscan-0.8.41 llvmlite-0.46.0 numba-0.63.1 pynndescent-0.5.13 sentence-transformers-5.2.0 smart_open-7.5.0 umap-learn-0.5.9.post2 wrapt-2.0.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install bertopic sentence-transformers umap-learn hdbscan gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIRS = [\"2013\", \"2014\", \"2015\"]   # or one folder if you prefer\n",
    "OUT_DIR = \"outputs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define EU list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "EU_COUNTRIES = {\n",
    "    \"Austria\",\"Belgium\",\"Bulgaria\",\"Croatia\",\"Cyprus\",\"Czech Republic\",\"Denmark\",\n",
    "    \"Estonia\",\"Finland\",\"France\",\"Germany\",\"Greece\",\"Hungary\",\"Ireland\",\"Italy\",\n",
    "    \"Latvia\",\"Lithuania\",\"Luxembourg\",\"Malta\",\"Netherlands\",\"Poland\",\"Portugal\",\n",
    "    \"Romania\",\"Spain\",\"Sweden\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(585, ['2013/Afghanistan.txt', '2013/Albania.txt', '2013/Algeria.txt'])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = []\n",
    "for d in DATA_DIRS:\n",
    "    paths.extend(glob.glob(os.path.join(d, \"*.txt\")))\n",
    "paths = sorted(paths)\n",
    "\n",
    "len(paths), paths[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning + section split + chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_STYLE_RE = re.compile(r\"<(script|style)[^>]*>.*?</\\1>\", re.IGNORECASE | re.DOTALL)\n",
    "TAG_RE = re.compile(r\"<[^>]+>\")\n",
    "WS_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "def strip_html(html: str) -> str:\n",
    "    html = SCRIPT_STYLE_RE.sub(\" \", html)\n",
    "    text = TAG_RE.sub(\" \", html)\n",
    "    text = (text.replace(\"&amp;\", \"&\")\n",
    "                .replace(\"&nbsp;\", \" \")\n",
    "                .replace(\"&quot;\", '\"')\n",
    "                .replace(\"&lt;\", \"<\")\n",
    "                .replace(\"&gt;\", \">\"))\n",
    "    return WS_RE.sub(\" \", text).strip()\n",
    "\n",
    "def detect_sections(text: str):\n",
    "    headings = [\n",
    "        \"EXECUTIVE SUMMARY\", \"EXECUTIVE SUMMARY:\",\n",
    "        \"Section 1.\", \"SECTION 1.\", \"Section 1:\", \"SECTION 1:\",\n",
    "        \"Section 2.\", \"SECTION 2.\", \"Section 2:\", \"SECTION 2:\",\n",
    "        \"Section 3.\", \"SECTION 3.\", \"Section 3:\", \"SECTION 3:\",\n",
    "        \"Section 4.\", \"SECTION 4.\", \"Section 4:\", \"SECTION 4:\",\n",
    "        \"Section 5.\", \"SECTION 5.\", \"Section 5:\", \"SECTION 5:\",\n",
    "        \"Section 6.\", \"SECTION 6.\", \"Section 6:\", \"SECTION 6:\",\n",
    "        \"Section 7.\", \"SECTION 7.\", \"Section 7:\", \"SECTION 7:\",\n",
    "    ]\n",
    "    pattern = \"(\" + \"|\".join(re.escape(h) for h in headings) + \")\"\n",
    "    parts = re.split(pattern, text)\n",
    "\n",
    "    if len(parts) <= 1:\n",
    "        return [(\"FULL_TEXT\", text)]\n",
    "\n",
    "    sections = []\n",
    "    pre = parts[0].strip()\n",
    "    if pre:\n",
    "        sections.append((\"PREAMBLE\", pre))\n",
    "\n",
    "    i = 1\n",
    "    while i < len(parts) - 1:\n",
    "        title = parts[i].strip()\n",
    "        body = parts[i+1].strip()\n",
    "        if body:\n",
    "            sections.append((title, body))\n",
    "        i += 2\n",
    "    return sections\n",
    "\n",
    "def split_into_word_chunks(text: str, min_words=120, max_words=250):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        j = min(i + max_words, len(words))\n",
    "        chunk = words[i:j]\n",
    "        if len(chunk) >= min_words:\n",
    "            chunks.append(\" \".join(chunk))\n",
    "        i = j\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the full dataset table (ALL countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26785, 7),\n",
       "    year      country  is_eu            section      source_file  \\\n",
       " 0  2013  Afghanistan  False  EXECUTIVE SUMMARY  Afghanistan.txt   \n",
       " 1  2013  Afghanistan  False         Section 1.  Afghanistan.txt   \n",
       " 2  2013  Afghanistan  False         Section 1.  Afghanistan.txt   \n",
       " 3  2013  Afghanistan  False         Section 1.  Afghanistan.txt   \n",
       " 4  2013  Afghanistan  False         Section 1.  Afghanistan.txt   \n",
       " \n",
       "                                 chunk_id  \\\n",
       " 0  Afghanistan.txt::EXECUTIVE SUMMARY::0   \n",
       " 1         Afghanistan.txt::Section 1.::0   \n",
       " 2         Afghanistan.txt::Section 1.::1   \n",
       " 3         Afghanistan.txt::Section 1.::2   \n",
       " 4         Afghanistan.txt::Section 1.::3   \n",
       " \n",
       "                                                 text  \n",
       " 0  Share Afghanistan is an Islamic republic with ...  \n",
       " 1  Respect for the Integrity of the Person, Inclu...  \n",
       " 2  judges, prosecutors, and clerical staff. In Ju...  \n",
       " 3  were reports that insurgent groups were respon...  \n",
       " 4  with fists and electric cables; kicking; choki...  )"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for p in paths:\n",
    "    with open(p, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        year = f.readline().strip()\n",
    "        country = f.readline().strip()\n",
    "        html = f.read()\n",
    "\n",
    "    plain = strip_html(html)\n",
    "    for sec_title, sec_text in detect_sections(plain):\n",
    "        for k, ch in enumerate(split_into_word_chunks(sec_text, 120, 250)):\n",
    "            rows.append({\n",
    "                \"year\": year,\n",
    "                \"country\": country,\n",
    "                \"is_eu\": country in EU_COUNTRIES,\n",
    "                \"section\": sec_title,\n",
    "                \"source_file\": os.path.basename(p),\n",
    "                \"chunk_id\": f\"{os.path.basename(p)}::{sec_title}::{k}\",\n",
    "                \"text\": ch\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.shape, df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify counts (world vs EU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(year\n",
       " 2013    195\n",
       " 2014    195\n",
       " 2015    195\n",
       " Name: country, dtype: int64,\n",
       " np.float64(0.10293074481986186))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"year\"])[\"country\"].nunique(), df[\"is_eu\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2013    25\n",
       "2014    25\n",
       "2015    25\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many EU chunks?\n",
    "df[df[\"is_eu\"]].groupby(\"year\")[\"country\"].nunique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit BERTopic on the full corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 19:01:39,524 - BERTopic - Embedding - Transforming documents to embeddings.\n",
      "Batches: 100%|██████████| 838/838 [05:57<00:00,  2.34it/s]\n",
      "2026-01-01 19:07:38,915 - BERTopic - Embedding - Completed ✓\n",
      "2026-01-01 19:07:38,918 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2026-01-01 19:07:45,373 - BERTopic - Dimensionality - Completed ✓\n",
      "2026-01-01 19:07:45,379 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2026-01-01 19:07:49,056 - BERTopic - Cluster - Completed ✓\n",
      "2026-01-01 19:07:49,081 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2026-01-01 19:07:52,115 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>6702</td>\n",
       "      <td>-1_the_of_and_to</td>\n",
       "      <td>[the, of, and, to, in, on, government, for, th...</td>\n",
       "      <td>[forces generally acted with impunity, the Min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4241</td>\n",
       "      <td>0_labor_workers_work_union</td>\n",
       "      <td>[labor, workers, work, union, unions, employer...</td>\n",
       "      <td>[Worker Rights Share a. Freedom of Association...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2909</td>\n",
       "      <td>1_children_child_women_marriage</td>\n",
       "      <td>[children, child, women, marriage, age, birth,...</td>\n",
       "      <td>[law, property law, and in the judicial system...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1263</td>\n",
       "      <td>2_corruption_officials_public_disclosure</td>\n",
       "      <td>[corruption, officials, public, disclosure, in...</td>\n",
       "      <td>[Corruption and Lack of Transparency in Govern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>624</td>\n",
       "      <td>3_rape_violence_domestic_spousal</td>\n",
       "      <td>[rape, violence, domestic, spousal, women, dis...</td>\n",
       "      <td>[Discrimination, Societal Abuses, and Traffick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>574</td>\n",
       "      <td>4_prisoners_prison_prisons_inmates</td>\n",
       "      <td>[prisoners, prison, prisons, inmates, conditio...</td>\n",
       "      <td>[assaulting detainees or being complicit in pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>533</td>\n",
       "      <td>5_arrest_detainees_bail_detention</td>\n",
       "      <td>[arrest, detainees, bail, detention, police, h...</td>\n",
       "      <td>[According to media, a police investigation co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>388</td>\n",
       "      <td>6_police_security_arrest_forces</td>\n",
       "      <td>[police, security, arrest, forces, responsible...</td>\n",
       "      <td>[had reasonable access to visitors, could atte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>374</td>\n",
       "      <td>7_elections_participation_women_minorities</td>\n",
       "      <td>[elections, participation, women, minorities, ...</td>\n",
       "      <td>[Respect for Political Rights: The Right of Ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>368</td>\n",
       "      <td>8_prisoners_prison_prisons_monitoring</td>\n",
       "      <td>[prisoners, prison, prisons, monitoring, compl...</td>\n",
       "      <td>[since the prison administration did not maint...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                        Name  \\\n",
       "0     -1   6702                            -1_the_of_and_to   \n",
       "1      0   4241                  0_labor_workers_work_union   \n",
       "2      1   2909             1_children_child_women_marriage   \n",
       "3      2   1263    2_corruption_officials_public_disclosure   \n",
       "4      3    624            3_rape_violence_domestic_spousal   \n",
       "5      4    574          4_prisoners_prison_prisons_inmates   \n",
       "6      5    533           5_arrest_detainees_bail_detention   \n",
       "7      6    388             6_police_security_arrest_forces   \n",
       "8      7    374  7_elections_participation_women_minorities   \n",
       "9      8    368       8_prisoners_prison_prisons_monitoring   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [the, of, and, to, in, on, government, for, th...   \n",
       "1  [labor, workers, work, union, unions, employer...   \n",
       "2  [children, child, women, marriage, age, birth,...   \n",
       "3  [corruption, officials, public, disclosure, in...   \n",
       "4  [rape, violence, domestic, spousal, women, dis...   \n",
       "5  [prisoners, prison, prisons, inmates, conditio...   \n",
       "6  [arrest, detainees, bail, detention, police, h...   \n",
       "7  [police, security, arrest, forces, responsible...   \n",
       "8  [elections, participation, women, minorities, ...   \n",
       "9  [prisoners, prison, prisons, monitoring, compl...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [forces generally acted with impunity, the Min...  \n",
       "1  [Worker Rights Share a. Freedom of Association...  \n",
       "2  [law, property law, and in the judicial system...  \n",
       "3  [Corruption and Lack of Transparency in Govern...  \n",
       "4  [Discrimination, Societal Abuses, and Traffick...  \n",
       "5  [assaulting detainees or being complicit in pu...  \n",
       "6  [According to media, a police investigation co...  \n",
       "7  [had reasonable access to visitors, could atte...  \n",
       "8  [Respect for Political Rights: The Right of Ci...  \n",
       "9  [since the prison administration did not maint...  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "docs_all = df[\"text\"].tolist()\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedder,\n",
    "    calculate_probabilities=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "topics, _ = topic_model.fit_transform(docs_all)\n",
    "df[\"topic\"] = topics\n",
    "\n",
    "topic_info = topic_model.get_topic_info()\n",
    "topic_info.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>7490</td>\n",
       "      <td>-1_the_of_and_to</td>\n",
       "      <td>[the, of, and, to, in, government, for, on, th...</td>\n",
       "      <td>[Respect for the Integrity of the Person, Incl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4240</td>\n",
       "      <td>0_labor_workers_work_union</td>\n",
       "      <td>[labor, workers, work, union, unions, employer...</td>\n",
       "      <td>[and trade union officials in identifying forc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1271</td>\n",
       "      <td>1_corruption_officials_public_disclosure</td>\n",
       "      <td>[corruption, officials, public, disclosure, in...</td>\n",
       "      <td>[Corruption and Lack of Transparency in Govern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>734</td>\n",
       "      <td>2_hiv_lgbt_aids_lgbti</td>\n",
       "      <td>[hiv, lgbt, aids, lgbti, discrimination, orien...</td>\n",
       "      <td>[public schools provided special education cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>618</td>\n",
       "      <td>3_prisoners_prison_prisons_inmates</td>\n",
       "      <td>[prisoners, prison, prisons, inmates, conditio...</td>\n",
       "      <td>[Respect for the Integrity of the Person, Incl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>182</td>\n",
       "      <td>10</td>\n",
       "      <td>182_nuer_spla_jonglei_dinka</td>\n",
       "      <td>[nuer, spla, jonglei, dinka, pg, civilians, mu...</td>\n",
       "      <td>[gathered on the basis of their ethnicity in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>183</td>\n",
       "      <td>10</td>\n",
       "      <td>183_birth_reproductive_abuse_child</td>\n",
       "      <td>[birth, reproductive, abuse, child, citizenshi...</td>\n",
       "      <td>[Interior, and the Ministry of Justice. Sexual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>184</td>\n",
       "      <td>10</td>\n",
       "      <td>184_arab_students_jnf_education</td>\n",
       "      <td>[arab, students, jnf, education, schools, jewi...</td>\n",
       "      <td>[school in the city, although 20 percent of re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>185</td>\n",
       "      <td>10</td>\n",
       "      <td>185_diecp_ipid_saps_officers</td>\n",
       "      <td>[diecp, ipid, saps, officers, police, cases, f...</td>\n",
       "      <td>[power at the end of each 90-day period follow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>186</td>\n",
       "      <td>10</td>\n",
       "      <td>186_pretrial_detention_bail_months</td>\n",
       "      <td>[pretrial, detention, bail, months, days, tria...</td>\n",
       "      <td>[will be committed. A warrant is not required,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                      Name  \\\n",
       "0       -1   7490                          -1_the_of_and_to   \n",
       "1        0   4240                0_labor_workers_work_union   \n",
       "2        1   1271  1_corruption_officials_public_disclosure   \n",
       "3        2    734                     2_hiv_lgbt_aids_lgbti   \n",
       "4        3    618        3_prisoners_prison_prisons_inmates   \n",
       "..     ...    ...                                       ...   \n",
       "183    182     10               182_nuer_spla_jonglei_dinka   \n",
       "184    183     10        183_birth_reproductive_abuse_child   \n",
       "185    184     10           184_arab_students_jnf_education   \n",
       "186    185     10              185_diecp_ipid_saps_officers   \n",
       "187    186     10        186_pretrial_detention_bail_months   \n",
       "\n",
       "                                        Representation  \\\n",
       "0    [the, of, and, to, in, government, for, on, th...   \n",
       "1    [labor, workers, work, union, unions, employer...   \n",
       "2    [corruption, officials, public, disclosure, in...   \n",
       "3    [hiv, lgbt, aids, lgbti, discrimination, orien...   \n",
       "4    [prisoners, prison, prisons, inmates, conditio...   \n",
       "..                                                 ...   \n",
       "183  [nuer, spla, jonglei, dinka, pg, civilians, mu...   \n",
       "184  [birth, reproductive, abuse, child, citizenshi...   \n",
       "185  [arab, students, jnf, education, schools, jewi...   \n",
       "186  [diecp, ipid, saps, officers, police, cases, f...   \n",
       "187  [pretrial, detention, bail, months, days, tria...   \n",
       "\n",
       "                                   Representative_Docs  \n",
       "0    [Respect for the Integrity of the Person, Incl...  \n",
       "1    [and trade union officials in identifying forc...  \n",
       "2    [Corruption and Lack of Transparency in Govern...  \n",
       "3    [public schools provided special education cla...  \n",
       "4    [Respect for the Integrity of the Person, Incl...  \n",
       "..                                                 ...  \n",
       "183  [gathered on the basis of their ethnicity in t...  \n",
       "184  [Interior, and the Ministry of Justice. Sexual...  \n",
       "185  [school in the city, although 20 percent of re...  \n",
       "186  [power at the end of each 90-day period follow...  \n",
       "187  [will be committed. A warrant is not required,...  \n",
       "\n",
       "[188 rows x 5 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The model produced a large number of topics (188 including outliers). Topic sizes are highly imbalanced: a few topics are very large (e.g., labor rights), while many topics are small (around 10 chunks). For reporting and interpretation, we focus on the most frequent topics and treat small topics as niche/country-specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coherence + diversity 188 topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def topic_diversity(topic_words, topk=10):\n",
    "    all_words = []\n",
    "    for wlist in topic_words:\n",
    "        all_words.extend(wlist[:topk])\n",
    "    return len(set(all_words)) / max(1, len(all_words))\n",
    "\n",
    "def coherence_cv(tokenized_docs, topic_words):\n",
    "    dictionary = Dictionary(tokenized_docs)\n",
    "    corpus = [dictionary.doc2bow(toks) for toks in tokenized_docs]\n",
    "    cm = CoherenceModel(\n",
    "        topics=topic_words,\n",
    "        texts=tokenized_docs,\n",
    "        corpus=corpus,\n",
    "        dictionary=dictionary,\n",
    "        coherence=\"c_v\"\n",
    "    )\n",
    "    return float(cm.get_coherence())\n",
    "\n",
    "topic_words = [get_topic_words(topic_model, tid, 20) for tid in valid_topic_ids]\n",
    "tokenized = [d.split() for d in docs_all]\n",
    "\n",
    "metrics = {\n",
    "    \"coherence_c_v\": coherence_cv(tokenized, topic_words),\n",
    "    \"topic_diversity_top10\": topic_diversity(topic_words, topk=10),\n",
    "    \"n_topics_excluding_outliers\": len(valid_topic_ids)\n",
    "}\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This topic-size pattern often happens because:\n",
    "the dataset is diverse (many countries, many issues),\n",
    "chunking creates many small “mini-documents”,\n",
    "HDBSCAN clustering prefers to split rare patterns into separate small clusters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Topics to the “main topics”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>share</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4240</td>\n",
       "      <td>0.219746</td>\n",
       "      <td>0_labor_workers_the_and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2417</td>\n",
       "      <td>0.125266</td>\n",
       "      <td>1_prisoners_to_the_prison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1807</td>\n",
       "      <td>0.093651</td>\n",
       "      <td>2_corruption_the_and_of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1387</td>\n",
       "      <td>0.071884</td>\n",
       "      <td>3_the_in_of_and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.060741</td>\n",
       "      <td>4_rape_violence_domestic_women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>1114</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>5_freedom_the_and_of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>997</td>\n",
       "      <td>0.051671</td>\n",
       "      <td>6_women_children_birth_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>905</td>\n",
       "      <td>0.046903</td>\n",
       "      <td>7_refugees_asylum_the_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>823</td>\n",
       "      <td>0.042654</td>\n",
       "      <td>8_elections_political_the_parties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>750</td>\n",
       "      <td>0.038870</td>\n",
       "      <td>9_hiv_lgbt_discrimination_aids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>636</td>\n",
       "      <td>0.032962</td>\n",
       "      <td>10_disabilities_with_persons_the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>634</td>\n",
       "      <td>0.032858</td>\n",
       "      <td>11_child_children_age_marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>549</td>\n",
       "      <td>0.028453</td>\n",
       "      <td>12_human_rights_government_international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>462</td>\n",
       "      <td>0.023944</td>\n",
       "      <td>13_in_and_the_forces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>318</td>\n",
       "      <td>0.016481</td>\n",
       "      <td>14_and_problems_human_security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>259</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>15_roma_romani_the_in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>182</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>16_anti_jewish_semitic_the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>157</td>\n",
       "      <td>0.008137</td>\n",
       "      <td>17_citizenship_stateless_persons_country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>135</td>\n",
       "      <td>0.006997</td>\n",
       "      <td>18_idps_displaced_to_in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>128</td>\n",
       "      <td>0.006634</td>\n",
       "      <td>19_land_property_restitution_the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>119</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>20_indigenous_land_lands_the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>21_dalit_dalits_caste_manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>22_korea_dprk_kim_north</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>23_constitutional_court_the_of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>24_papua_flag_separatist_rms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>25_bedouin_villages_demolitions_bedouins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>26_janeiro_rio_de_police</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>27_han_xuar_minority_ethnic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>28_arab_students_education_schools</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count     share                                      Name\n",
       "1       0   4240  0.219746                   0_labor_workers_the_and\n",
       "2       1   2417  0.125266                 1_prisoners_to_the_prison\n",
       "3       2   1807  0.093651                   2_corruption_the_and_of\n",
       "4       3   1387  0.071884                           3_the_in_of_and\n",
       "5       4   1172  0.060741            4_rape_violence_domestic_women\n",
       "6       5   1114  0.057735                      5_freedom_the_and_of\n",
       "7       6    997  0.051671                 6_women_children_birth_to\n",
       "8       7    905  0.046903                  7_refugees_asylum_the_to\n",
       "9       8    823  0.042654         8_elections_political_the_parties\n",
       "10      9    750  0.038870            9_hiv_lgbt_discrimination_aids\n",
       "11     10    636  0.032962          10_disabilities_with_persons_the\n",
       "12     11    634  0.032858            11_child_children_age_marriage\n",
       "13     12    549  0.028453  12_human_rights_government_international\n",
       "14     13    462  0.023944                      13_in_and_the_forces\n",
       "15     14    318  0.016481            14_and_problems_human_security\n",
       "16     15    259  0.013423                     15_roma_romani_the_in\n",
       "17     16    182  0.009432                16_anti_jewish_semitic_the\n",
       "18     17    157  0.008137  17_citizenship_stateless_persons_country\n",
       "19     18    135  0.006997                   18_idps_displaced_to_in\n",
       "20     19    128  0.006634          19_land_property_restitution_the\n",
       "21     20    119  0.006167              20_indigenous_land_lands_the\n",
       "22     21     17  0.000881              21_dalit_dalits_caste_manual\n",
       "23     22     16  0.000829                   22_korea_dprk_kim_north\n",
       "24     23     13  0.000674            23_constitutional_court_the_of\n",
       "25     24     13  0.000674              24_papua_flag_separatist_rms\n",
       "26     25     13  0.000674  25_bedouin_villages_demolitions_bedouins\n",
       "27     26     12  0.000622                  26_janeiro_rio_de_police\n",
       "28     27     10  0.000518               27_han_xuar_minority_ethnic\n",
       "29     28     10  0.000518        28_arab_students_education_schools"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_info = topic_model.get_topic_info().copy()\n",
    "\n",
    "# Exclude outliers for interpretation\n",
    "main_topics = topic_info[topic_info[\"Topic\"] != -1].copy()\n",
    "\n",
    "# Add share\n",
    "main_topics[\"share\"] = main_topics[\"Count\"] / main_topics[\"Count\"].sum()\n",
    "\n",
    "main_topics.head(30)[[\"Topic\",\"Count\",\"share\",\"Name\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge/limit topics\n",
    "BERTopic has a built-in way to reduce the number of topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 17:40:15,204 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2026-01-01 17:40:15,259 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2026-01-01 17:40:17,999 - BERTopic - Representation - Completed ✓\n",
      "2026-01-01 17:40:18,005 - BERTopic - Topic reduction - Reduced number of topics from 188 to 30\n"
     ]
    }
   ],
   "source": [
    "# Reduce topics to a more interpretable number (e.g., 30)\n",
    "topic_model_reduced = topic_model.reduce_topics(df[\"text\"].tolist(), nr_topics=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">To improve interpretability, we reduced the number of topics from 188 to 30 using BERTopic topic reduction. This merges small similar clusters into broader themes, making the results easier to summarize while preserving the main patterns.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topic size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sizes = main_topics[\"Count\"].values\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(sizes, bins=30)\n",
    "plt.title(\"Distribution of topic sizes (excluding outliers)\")\n",
    "plt.xlabel(\"Number of chunks in topic\")\n",
    "plt.ylabel(\"Number of topics\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topic size distribution is highly imbalanced: a small number of topics cover a large part of the corpus, while most topics are small. This suggests the dataset contains both global recurring themes and many niche country-specific issues.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify outlier percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.2796341235766287)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = topic_info[\"Count\"].sum()\n",
    "outliers = int(topic_info.loc[topic_info[\"Topic\"] == -1, \"Count\"].iloc[0])\n",
    "outlier_rate = outliers / total\n",
    "outlier_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Approximately 28% of chunks were classified as outliers (-1) and were excluded from topic comparisons.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper to view topic words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['labor', 'workers', 'work', 'union', 'unions', 'employers', 'minimum', 'sector', 'employment', 'forced']\n",
      "1 ['corruption', 'officials', 'public', 'disclosure', 'information', 'financial', 'transparency', 'assets', 'corrupt', 'anticorruption']\n",
      "2 ['hiv', 'lgbt', 'aids', 'lgbti', 'discrimination', 'orientation', 'transgender', 'identity', 'stigma', 'gay']\n",
      "3 ['prisoners', 'prison', 'prisons', 'inmates', 'conditions', 'facilities', 'held', 'overcrowding', 'detention', 'detainees']\n",
      "4 ['rape', 'violence', 'domestic', 'spousal', 'women', 'discrimination', 'gender', 'race', 'societal', 'sexual']\n",
      "5 ['arrest', 'detainees', 'bail', 'detention', 'hours', 'police', 'suspects', 'authorities', 'suspect', 'detainee']\n",
      "6 ['elections', 'participation', 'women', 'minorities', 'political', 'seats', 'cabinet', 'parties', 'parliament', 'seat']\n",
      "7 ['prisoners', 'prison', 'prisons', 'monitoring', 'complaints', 'visits', 'permitted', 'detention', 'conditions', 'independent']\n"
     ]
    }
   ],
   "source": [
    "def get_topic_words(model, topic_id, topn=10):\n",
    "    pairs = model.get_topic(topic_id) or []\n",
    "    return [w for w, _ in pairs[:topn]]\n",
    "\n",
    "valid_topic_ids = [t for t in topic_model.get_topics().keys() if t != -1]\n",
    "for tid in valid_topic_ids[:8]:\n",
    "    print(tid, get_topic_words(topic_model, tid, 10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation reduced topics\n",
    "### Coherence + diversity\n",
    "\n",
    "Coherence measures if top words inside a topic match one theme. Higher coherence means topics are easier to understand. (Are the topic words connected and meaningful together?)\n",
    "- Higher coherence value = usually better\n",
    "\n",
    "\n",
    "Topic diversity shows how many unique words appear in top words of topics. Higher diversity means topics are not copies. (Are topics different from each other, or are they repeating the same words?)\n",
    "- Higher diversity = less repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coherence_c_v': 0.47323458226538656,\n",
       " 'topic_diversity_top10': 0.5586206896551724,\n",
       " 'n_topics_excluding_outliers': 29,\n",
       " 'skipped_topics_due_to_empty_words': 0}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def get_topic_words_safe(model, topic_id, topn=20):\n",
    "    pairs = model.get_topic(topic_id)\n",
    "    if not pairs:\n",
    "        return []\n",
    "    return [w for (w, _) in pairs[:topn] if isinstance(w, str) and w.strip()]\n",
    "\n",
    "def build_valid_topic_words(model, topn=20, min_words=5):\n",
    "    topic_words = []\n",
    "    topic_ids = []\n",
    "    for tid in model.get_topics().keys():\n",
    "        if tid == -1:\n",
    "            continue\n",
    "        words = get_topic_words_safe(model, tid, topn=topn)\n",
    "        # keep only topics that have enough usable words\n",
    "        if len(words) >= min_words:\n",
    "            topic_words.append(words)\n",
    "            topic_ids.append(tid)\n",
    "    return topic_ids, topic_words\n",
    "\n",
    "def topic_diversity(topic_words, topk=10):\n",
    "    all_words = []\n",
    "    for wlist in topic_words:\n",
    "        all_words.extend(wlist[:topk])\n",
    "    return len(set(all_words)) / max(1, len(all_words))\n",
    "\n",
    "def coherence_cv(tokenized_docs, topic_words):\n",
    "    dictionary = Dictionary(tokenized_docs)\n",
    "    corpus = [dictionary.doc2bow(toks) for toks in tokenized_docs]\n",
    "    cm = CoherenceModel(\n",
    "        topics=topic_words,\n",
    "        texts=tokenized_docs,\n",
    "        corpus=corpus,\n",
    "        dictionary=dictionary,\n",
    "        coherence=\"c_v\"\n",
    "    )\n",
    "    return float(cm.get_coherence())\n",
    "\n",
    "# IMPORTANT: rebuild topics from the (reduced) model\n",
    "topic_ids_eval, topic_words_eval = build_valid_topic_words(topic_model, topn=20, min_words=5)\n",
    "\n",
    "tokenized = [d.split() for d in docs_all]\n",
    "\n",
    "metrics = {\n",
    "    \"coherence_c_v\": coherence_cv(tokenized, topic_words_eval),\n",
    "    \"topic_diversity_top10\": topic_diversity(topic_words_eval, topk=10),\n",
    "    \"n_topics_excluding_outliers\": len(topic_ids_eval),\n",
    "    \"skipped_topics_due_to_empty_words\": (len([t for t in topic_model.get_topics().keys() if t != -1]) - len(topic_ids_eval))\n",
    "}\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We first trained BERTopic and obtained 188 topics (excluding outliers). This produced more fine-grained themes and higher quantitative topic quality metrics. However, many topics were very small and difficult to interpret. Therefore, we reduced the model to 30 topics to improve interpretability. After reduction, coherence (c_v = 0.473) and topic diversity (0.559) decreased, which is expected because reduced topics are broader and share more general vocabulary. We use the reduced model for reporting and comparisons, while the full model supports detailed exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability \n",
    "\n",
    "Simple meaning: If we rerun the model, do we get similar topics? \n",
    "Higher overlap = more stable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stability_mean_best_jaccard': 0.8707070707070707,\n",
       " 'stability_median_best_jaccard': 0.8181818181818182}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jaccard(a, b):\n",
    "    a, b = set(a), set(b)\n",
    "    return len(a & b) / max(1, len(a | b))\n",
    "\n",
    "def run_model_with_seed(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    idx = np.random.permutation(len(docs_all))\n",
    "    docs_shuffled = [docs_all[i] for i in idx]\n",
    "    tm = BERTopic(embedding_model=embedder, verbose=False)\n",
    "    tm.fit_transform(docs_shuffled)\n",
    "    valid = [tid for tid in tm.get_topics().keys() if tid != -1]\n",
    "    return {tid: get_topic_words(tm, tid, 15) for tid in valid}\n",
    "\n",
    "w1 = run_model_with_seed(1)\n",
    "w2 = run_model_with_seed(2)\n",
    "\n",
    "scores = []\n",
    "for t1, words1 in list(w1.items())[:15]:\n",
    "    best = 0.0\n",
    "    for t2, words2 in w2.items():\n",
    "        best = max(best, jaccard(words1, words2))\n",
    "    scores.append(best)\n",
    "\n",
    "{\"stability_mean_best_jaccard\": float(np.mean(scores)),\n",
    " \"stability_median_best_jaccard\": float(np.median(scores))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tested stability by fitting the model twice with different shuffle. The overlap was 0.81 . This shows the topics are stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EU-focused interpretation \n",
    "### Topic share inside EU vs non-EU\n",
    "\n",
    "Positive delta: topic is more common in EU\n",
    "Negative delta: topic is more common in non-EU\n",
    "\n",
    "We compared topic shares between EU and non-EU reports. Some topics appear more in EU (delta positive), others more in non-EU (delta negative).”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 838/838 [05:59<00:00,  2.33it/s]\n"
     ]
    }
   ],
   "source": [
    "docs_all = df[\"text\"].tolist()\n",
    "\n",
    "# After reduce_topics, re-transform to get the updated topic assignments\n",
    "topics_new, _ = topic_model.transform(docs_all)\n",
    "\n",
    "df[\"topic_reduced\"] = topics_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def topic_share(subdf: pd.DataFrame, label: str, topic_col=\"topic_reduced\"):\n",
    "    t = (subdf[subdf[topic_col] != -1]\n",
    "         .groupby(topic_col).size().reset_index(name=\"n\"))\n",
    "    t[\"share\"] = t[\"n\"] / t[\"n\"].sum()\n",
    "    t[\"group\"] = label\n",
    "    return t.rename(columns={topic_col: \"topic\"})\n",
    "\n",
    "eu = topic_share(df[df[\"is_eu\"]], \"EU\", topic_col=\"topic_reduced\")\n",
    "non_eu = topic_share(df[~df[\"is_eu\"]], \"Non-EU\", topic_col=\"topic_reduced\")\n",
    "\n",
    "compare = pd.concat([eu, non_eu], ignore_index=True)\n",
    "compare = compare.pivot_table(index=\"topic\", columns=\"group\", values=\"share\", fill_value=0.0).reset_index()\n",
    "compare[\"delta_EU_minus_NonEU\"] = compare.get(\"EU\", 0.0) - compare.get(\"Non-EU\", 0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing stopwords from topic words\n",
    "\n",
    ">Because our main model uses transformer embeddings, we avoided heavy stopword removal before embedding to preserve contextual meaning. Instead, we applied stopword filtering at the topic representation stage to improve interpretability of topic keywords.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>group</th>\n",
       "      <th>topic</th>\n",
       "      <th>EU</th>\n",
       "      <th>Non-EU</th>\n",
       "      <th>delta_EU_minus_NonEU</th>\n",
       "      <th>top_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.068137</td>\n",
       "      <td>0.006955</td>\n",
       "      <td>0.061183</td>\n",
       "      <td>roma, romani, ethnic, education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.049510</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.044816</td>\n",
       "      <td>anti, jewish, semitic, holocaust, semitism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.070098</td>\n",
       "      <td>0.044161</td>\n",
       "      <td>0.025937</td>\n",
       "      <td>refugees, asylum, seekers, refugee, unhcr, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.135294</td>\n",
       "      <td>0.124080</td>\n",
       "      <td>0.011214</td>\n",
       "      <td>prisoners, prison, detention, detainees, autho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.025490</td>\n",
       "      <td>0.015416</td>\n",
       "      <td>0.010074</td>\n",
       "      <td>problems, human, security, rights, forces, abu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>0.007346</td>\n",
       "      <td>citizenship, stateless, persons, country, bido...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>constitutional, court, obh, retirement, justic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.038235</td>\n",
       "      <td>0.032338</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>disabilities, persons, mental, education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.097549</td>\n",
       "      <td>0.093190</td>\n",
       "      <td>0.004359</td>\n",
       "      <td>corruption, public, officials, government, police</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.062255</td>\n",
       "      <td>0.060562</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>rape, violence, domestic, women, sexual, victims</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>land, property, restitution, compensation, gov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.038725</td>\n",
       "      <td>0.038887</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>hiv, lgbt, discrimination, aids, persons, lgbt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.027941</td>\n",
       "      <td>0.028513</td>\n",
       "      <td>-0.000572</td>\n",
       "      <td>human, rights, government, international, ngos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>han, xuar, minority, ethnic, chinese, autonomo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>arab, students, education, schools, percent, j...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "group  topic        EU    Non-EU  delta_EU_minus_NonEU  \\\n",
       "15        15  0.068137  0.006955              0.061183   \n",
       "16        16  0.049510  0.004694              0.044816   \n",
       "7          7  0.070098  0.044161              0.025937   \n",
       "1          1  0.135294  0.124080              0.011214   \n",
       "14        14  0.025490  0.015416              0.010074   \n",
       "17        17  0.014706  0.007360              0.007346   \n",
       "23        23  0.006373  0.000000              0.006373   \n",
       "10        10  0.038235  0.032338              0.005897   \n",
       "2          2  0.097549  0.093190              0.004359   \n",
       "4          4  0.062255  0.060562              0.001693   \n",
       "19        19  0.007843  0.006491              0.001352   \n",
       "9          9  0.038725  0.038887             -0.000162   \n",
       "12        12  0.027941  0.028513             -0.000572   \n",
       "27        27  0.000000  0.000580             -0.000580   \n",
       "28        28  0.000000  0.000580             -0.000580   \n",
       "\n",
       "group                                          top_words  \n",
       "15                       roma, romani, ethnic, education  \n",
       "16            anti, jewish, semitic, holocaust, semitism  \n",
       "7      refugees, asylum, seekers, refugee, unhcr, pro...  \n",
       "1      prisoners, prison, detention, detainees, autho...  \n",
       "14     problems, human, security, rights, forces, abu...  \n",
       "17     citizenship, stateless, persons, country, bido...  \n",
       "23     constitutional, court, obh, retirement, justic...  \n",
       "10              disabilities, persons, mental, education  \n",
       "2      corruption, public, officials, government, police  \n",
       "4       rape, violence, domestic, women, sexual, victims  \n",
       "19     land, property, restitution, compensation, gov...  \n",
       "9      hiv, lgbt, discrimination, aids, persons, lgbt...  \n",
       "12     human, rights, government, international, ngos...  \n",
       "27     han, xuar, minority, ethnic, chinese, autonomo...  \n",
       "28     arab, students, education, schools, percent, j...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOP = set(\"\"\"\n",
    "the of and to in for on with as at by from is are was were be been being this that it its\n",
    "a an or not have has had may can will would should could\n",
    "\"\"\".split())\n",
    "\n",
    "def get_topic_words_clean(model, topic_id, topn=10):\n",
    "    pairs = model.get_topic(topic_id) or []\n",
    "    words = [w for (w, _) in pairs if isinstance(w, str)]\n",
    "    words = [w for w in words if w.lower() not in STOP and len(w) > 2]\n",
    "    return words[:topn]\n",
    "\n",
    "compare[\"top_words\"] = compare[\"topic\"].apply(lambda t: \", \".join(get_topic_words_clean(topic_model, int(t), 10)))\n",
    "compare.sort_values(\"delta_EU_minus_NonEU\", ascending=False).head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">EU reports show strong emphasis on minority integration (Roma/Romani), anti-Semitism, and asylum/refugee protection. Many other themes such as prisons, corruption, and violence against women are global topics and appear in both EU and non-EU reports at similar rates. This confirms that the topic model identifies both region-specific and universal human-rights themes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stopword-aware topic words helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#  stopword list (English + report boilerplate)\n",
    "STOP = set(\"\"\"\n",
    "a an and are as at be been being by can could did do does doing for from had has have having\n",
    "he her hers herself him himself his how i if in into is it its itself just me more most my\n",
    "myself no nor not of on once only or other our ours ourselves out over own same she should\n",
    "so some such than that the their theirs them themselves then there these they this those\n",
    "through to too under until up very was we were what when where which while who whom why will with would you your yours yourself yourselves\n",
    "\n",
    "section executive summary share government law provides including respect rights person persons\n",
    "\"\"\".split())\n",
    "\n",
    "def clean_tokens(words):\n",
    "    \"\"\"Keep only meaningful tokens: letters only, not stopwords, length>=3.\"\"\"\n",
    "    out = []\n",
    "    for w in words:\n",
    "        w = w.lower().strip()\n",
    "        w = re.sub(r\"[^a-z]+\", \"\", w)      # remove punctuation/numbers\n",
    "        if not w:\n",
    "            continue\n",
    "        if w in STOP:\n",
    "            continue\n",
    "        if len(w) < 3:\n",
    "            continue\n",
    "        out.append(w)\n",
    "    return out\n",
    "\n",
    "def get_topic_words_clean(model, topic_id, topn=10):\n",
    "    \"\"\"\n",
    "    Return topn clean words for a topic. Uses BERTopic get_topic().\n",
    "    \"\"\"\n",
    "    pairs = model.get_topic(int(topic_id)) or []\n",
    "    raw = [w for (w, _) in pairs]\n",
    "    cleaned = clean_tokens(raw)\n",
    "    return cleaned[:topn]\n",
    "\n",
    "def topic_words_str(model, topic_id, topn=10):\n",
    "    \"\"\"Convenience: returns a comma-separated string of clean topic words.\"\"\"\n",
    "    return \", \".join(get_topic_words_clean(model, topic_id, topn=topn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics more common in non-EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>group</th>\n",
       "      <th>topic</th>\n",
       "      <th>EU</th>\n",
       "      <th>Non-EU</th>\n",
       "      <th>delta_EU_minus_NonEU</th>\n",
       "      <th>top_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.022549</td>\n",
       "      <td>0.077717</td>\n",
       "      <td>-0.055168</td>\n",
       "      <td>police, torture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.222544</td>\n",
       "      <td>-0.026466</td>\n",
       "      <td>labor, workers, work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.026717</td>\n",
       "      <td>-0.026227</td>\n",
       "      <td>forces, killed, civilians, armed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.032843</td>\n",
       "      <td>0.053897</td>\n",
       "      <td>-0.021054</td>\n",
       "      <td>women, children, birth, percent, child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.044608</td>\n",
       "      <td>0.059287</td>\n",
       "      <td>-0.014679</td>\n",
       "      <td>freedom, internet, media, press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.030882</td>\n",
       "      <td>0.044045</td>\n",
       "      <td>-0.013163</td>\n",
       "      <td>elections, political, parties, election, parti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007824</td>\n",
       "      <td>-0.007824</td>\n",
       "      <td>idps, displaced, displacement, idp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>-0.006897</td>\n",
       "      <td>indigenous, land, lands, communities, afro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.030392</td>\n",
       "      <td>0.033150</td>\n",
       "      <td>-0.002758</td>\n",
       "      <td>child, children, age, marriage, years, sexual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>-0.000985</td>\n",
       "      <td>dalit, dalits, caste, manual, upper, scavenger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>-0.000927</td>\n",
       "      <td>korea, dprk, kim, north, jong, korean, jang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>-0.000753</td>\n",
       "      <td>bedouin, villages, demolitions, bedouins, unre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>-0.000753</td>\n",
       "      <td>papua, flag, separatist, rms, aceh, maluku, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>-0.000695</td>\n",
       "      <td>janeiro, rio, police, officers, paulo, state, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>arab, students, education, schools, percent, j...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "group  topic        EU    Non-EU  delta_EU_minus_NonEU  \\\n",
       "3          3  0.022549  0.077717             -0.055168   \n",
       "0          0  0.196078  0.222544             -0.026466   \n",
       "13        13  0.000490  0.026717             -0.026227   \n",
       "6          6  0.032843  0.053897             -0.021054   \n",
       "5          5  0.044608  0.059287             -0.014679   \n",
       "8          8  0.030882  0.044045             -0.013163   \n",
       "18        18  0.000000  0.007824             -0.007824   \n",
       "20        20  0.000000  0.006897             -0.006897   \n",
       "11        11  0.030392  0.033150             -0.002758   \n",
       "21        21  0.000000  0.000985             -0.000985   \n",
       "22        22  0.000000  0.000927             -0.000927   \n",
       "25        25  0.000000  0.000753             -0.000753   \n",
       "24        24  0.000000  0.000753             -0.000753   \n",
       "26        26  0.000000  0.000695             -0.000695   \n",
       "28        28  0.000000  0.000580             -0.000580   \n",
       "\n",
       "group                                          top_words  \n",
       "3                                        police, torture  \n",
       "0                                   labor, workers, work  \n",
       "13                      forces, killed, civilians, armed  \n",
       "6                 women, children, birth, percent, child  \n",
       "5                        freedom, internet, media, press  \n",
       "8      elections, political, parties, election, parti...  \n",
       "18                    idps, displaced, displacement, idp  \n",
       "20            indigenous, land, lands, communities, afro  \n",
       "11         child, children, age, marriage, years, sexual  \n",
       "21     dalit, dalits, caste, manual, upper, scavenger...  \n",
       "22           korea, dprk, kim, north, jong, korean, jang  \n",
       "25     bedouin, villages, demolitions, bedouins, unre...  \n",
       "24     papua, flag, separatist, rms, aceh, maluku, di...  \n",
       "26     janeiro, rio, police, officers, paulo, state, ...  \n",
       "28     arab, students, education, schools, percent, j...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topics more common in non-EU (most negative delta)\n",
    "compare[\"top_words\"] = compare[\"topic\"].apply(lambda t: topic_words_str(topic_model, t, 8))\n",
    "compare.sort_values(\"delta_EU_minus_NonEU\", ascending=True).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The comparison shows clear regional differences. EU reports emphasize minority discrimination topics (e.g., Roma, anti-Semitism, asylum systems—shown in the EU-heavy table), while non-EU reports emphasize more severe security and conflict themes such as torture, armed conflict, internal displacement, and indigenous land issues. At the same time, some topics like labor rights appear frequently in both groups, showing shared global human-rights categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for preventing over interpret\n",
    "We focus on topics with sufficient frequency (≥1% share) to avoid noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>group</th>\n",
       "      <th>topic</th>\n",
       "      <th>EU</th>\n",
       "      <th>Non-EU</th>\n",
       "      <th>delta_EU_minus_NonEU</th>\n",
       "      <th>top_words</th>\n",
       "      <th>abs_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.068137</td>\n",
       "      <td>0.006955</td>\n",
       "      <td>0.061183</td>\n",
       "      <td>roma, romani, ethnic, education</td>\n",
       "      <td>0.061183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.022549</td>\n",
       "      <td>0.077717</td>\n",
       "      <td>-0.055168</td>\n",
       "      <td>police, torture</td>\n",
       "      <td>0.055168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.049510</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.044816</td>\n",
       "      <td>anti, jewish, semitic, holocaust, semitism</td>\n",
       "      <td>0.044816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.222544</td>\n",
       "      <td>-0.026466</td>\n",
       "      <td>labor, workers, work</td>\n",
       "      <td>0.026466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.026717</td>\n",
       "      <td>-0.026227</td>\n",
       "      <td>forces, killed, civilians, armed</td>\n",
       "      <td>0.026227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.070098</td>\n",
       "      <td>0.044161</td>\n",
       "      <td>0.025937</td>\n",
       "      <td>refugees, asylum, seekers, refugee, unhcr, pro...</td>\n",
       "      <td>0.025937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.032843</td>\n",
       "      <td>0.053897</td>\n",
       "      <td>-0.021054</td>\n",
       "      <td>women, children, birth, percent, child</td>\n",
       "      <td>0.021054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.044608</td>\n",
       "      <td>0.059287</td>\n",
       "      <td>-0.014679</td>\n",
       "      <td>freedom, internet, media, press</td>\n",
       "      <td>0.014679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.030882</td>\n",
       "      <td>0.044045</td>\n",
       "      <td>-0.013163</td>\n",
       "      <td>elections, political, parties, election, parti...</td>\n",
       "      <td>0.013163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.135294</td>\n",
       "      <td>0.124080</td>\n",
       "      <td>0.011214</td>\n",
       "      <td>prisoners, prison, detention, detainees, autho...</td>\n",
       "      <td>0.011214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.025490</td>\n",
       "      <td>0.015416</td>\n",
       "      <td>0.010074</td>\n",
       "      <td>problems, human, security, forces, abuses, inc...</td>\n",
       "      <td>0.010074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>0.007346</td>\n",
       "      <td>citizenship, stateless, country, bidoon, born,...</td>\n",
       "      <td>0.007346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.038235</td>\n",
       "      <td>0.032338</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>disabilities, mental, education</td>\n",
       "      <td>0.005897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.097549</td>\n",
       "      <td>0.093190</td>\n",
       "      <td>0.004359</td>\n",
       "      <td>corruption, public, officials, police</td>\n",
       "      <td>0.004359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.030392</td>\n",
       "      <td>0.033150</td>\n",
       "      <td>-0.002758</td>\n",
       "      <td>child, children, age, marriage, years, sexual</td>\n",
       "      <td>0.002758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.062255</td>\n",
       "      <td>0.060562</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>rape, violence, domestic, women, sexual, victims</td>\n",
       "      <td>0.001693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.027941</td>\n",
       "      <td>0.028513</td>\n",
       "      <td>-0.000572</td>\n",
       "      <td>human, international, ngos, ombudsman</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.038725</td>\n",
       "      <td>0.038887</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>hiv, lgbt, discrimination, aids, lgbti, orient...</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "group  topic        EU    Non-EU  delta_EU_minus_NonEU  \\\n",
       "15        15  0.068137  0.006955              0.061183   \n",
       "3          3  0.022549  0.077717             -0.055168   \n",
       "16        16  0.049510  0.004694              0.044816   \n",
       "0          0  0.196078  0.222544             -0.026466   \n",
       "13        13  0.000490  0.026717             -0.026227   \n",
       "7          7  0.070098  0.044161              0.025937   \n",
       "6          6  0.032843  0.053897             -0.021054   \n",
       "5          5  0.044608  0.059287             -0.014679   \n",
       "8          8  0.030882  0.044045             -0.013163   \n",
       "1          1  0.135294  0.124080              0.011214   \n",
       "14        14  0.025490  0.015416              0.010074   \n",
       "17        17  0.014706  0.007360              0.007346   \n",
       "10        10  0.038235  0.032338              0.005897   \n",
       "2          2  0.097549  0.093190              0.004359   \n",
       "11        11  0.030392  0.033150             -0.002758   \n",
       "4          4  0.062255  0.060562              0.001693   \n",
       "12        12  0.027941  0.028513             -0.000572   \n",
       "9          9  0.038725  0.038887             -0.000162   \n",
       "\n",
       "group                                          top_words  abs_delta  \n",
       "15                       roma, romani, ethnic, education   0.061183  \n",
       "3                                        police, torture   0.055168  \n",
       "16            anti, jewish, semitic, holocaust, semitism   0.044816  \n",
       "0                                   labor, workers, work   0.026466  \n",
       "13                      forces, killed, civilians, armed   0.026227  \n",
       "7      refugees, asylum, seekers, refugee, unhcr, pro...   0.025937  \n",
       "6                 women, children, birth, percent, child   0.021054  \n",
       "5                        freedom, internet, media, press   0.014679  \n",
       "8      elections, political, parties, election, parti...   0.013163  \n",
       "1      prisoners, prison, detention, detainees, autho...   0.011214  \n",
       "14     problems, human, security, forces, abuses, inc...   0.010074  \n",
       "17     citizenship, stateless, country, bidoon, born,...   0.007346  \n",
       "10                       disabilities, mental, education   0.005897  \n",
       "2                  corruption, public, officials, police   0.004359  \n",
       "11         child, children, age, marriage, years, sexual   0.002758  \n",
       "4       rape, violence, domestic, women, sexual, victims   0.001693  \n",
       "12                 human, international, ngos, ombudsman   0.000572  \n",
       "9      hiv, lgbt, discrimination, aids, lgbti, orient...   0.000162  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare2 = compare.copy()\n",
    "compare2[\"abs_delta\"] = compare2[\"delta_EU_minus_NonEU\"].abs()\n",
    "compare2 = compare2.sort_values(\"abs_delta\", ascending=False)\n",
    "\n",
    "# keep only topics where either group share is at least 1%\n",
    "strong = compare2[(compare2[\"EU\"] >= 0.01) | (compare2[\"Non-EU\"] >= 0.01)]\n",
    "strong.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We compared topic frequency between EU and non-EU reports using normalized shares within each group. We then ranked topics by the absolute difference (abs_delta) and kept only topics with at least 1% share in either group to avoid noise. The results show clear regional patterns. EU reports contain more topics about Roma minority integration, asylum procedures, anti-Semitism, and European legal institutions such as the ECHR and ombudsman systems. Non-EU reports contain more content about labor rights, elections, protest restrictions, and conflict-related themes. These differences support that the model captures meaningful regional variation.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representative chunks per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0 Topic 0 labor, workers, work\n",
      " - Afghanistan 2013 Section 7. : Worker Rights Share a. Freedom of Association and the Right to Collective Bargaining The law provides for the right of workers to join and form independent unions and to conduct legal strikes and barg ...\n",
      " - Tunisia 2014 Section 7. : Worker Rights Share a. Freedom of Association and the Right to Collective Bargaining The law provides workers with the right to organize, form and join unions, and bargain collectively. The law allows ...\n",
      "\n",
      " 1 Topic 1 prisoners, prison, detention, detainees, authorities\n",
      " - Afghanistan 2013 Section 4. : Corruption and Lack of Transparency in Government Share The law provides criminal penalties for official corruption. The government did not implement the law effectively, and there were reports that o ...\n",
      " - Portugal 2014 Section 4. : Corruption and Lack of Transparency in Government Share The law provides criminal penalties for corruption by officials, and the government generally implemented these laws effectively. There were rep ...\n",
      "\n",
      " 2 Topic 2 corruption, public, officials, police\n",
      " - Lebanon 2014 Section 6. : curfew on Syrians’ movements in their neighborhoods to curb an increased number of robberies and to control security. Acts of Violence, Discrimination, and Other Abuses Based on Sexual Orientation and ...\n",
      " - Liberia 2014 Section 6. : violence or discrimination based on sexual orientation or gender identity. According to a local news report, on September 8, unknown assailants recognized and attacked a local LGBT-rights activist. Th ...\n",
      "\n",
      " 3 Topic 3 police, torture\n",
      " - Afghanistan 2013 Section 1. : 187 active Ministry of Interior detention facilities, and 30 juvenile rehabilitation centers. The total number of active detention facilities reportedly fluctuated from month to month. Overall, the Mi ...\n",
      " - Tunisia 2014 Section 1. : hold pretrial detainees together with individuals who had already been convicted. Overcrowded conditions were exacerbated by substandard lighting, ventilation, and heating problems in buildings not or ...\n",
      "\n",
      " 4 Topic 4 rape, violence, domestic, women, sexual, victims\n",
      " - Afghanistan 2013 Section 6. : Discrimination, Societal Abuses, and Trafficking in Persons Share While the constitution prohibits discrimination among citizens and provides for the equal rights of men and women, local customs and p ...\n",
      " - United Kingdom 2014 Section 6. : Discrimination, Societal Abuses, and Trafficking in Persons Share The law prohibits discrimination based on race, gender, disability, language, sexual orientation, or social status, and the government ...\n",
      "\n",
      " 5 Topic 5 freedom, internet, media, press\n",
      " - Afghanistan 2013 Section 1. : accountability that existed for security institutions, especially the ALP, although the Ministry of Interior took some measures at the end of the year to increase accountability of the ALP. For exampl ...\n",
      " - Zambia 2014 Section 1. : because defendants could not afford bail or were held on charges for which bail is not authorized, including murder, aggravated robbery, and violations of narcotics laws. The Law Association of Zambia ...\n",
      "\n",
      " 6 Topic 6 women, children, birth, percent, child\n",
      " - Afghanistan 2013 Section 3. : political parties registered with the Ministry of Justice. In April 2012 the Council of Ministers approved a regulation requiring political parties to open offices in at least 20 provinces within one  ...\n",
      " - Kenya 2014 Section 3. : overall success rate of women who vied for elected positions was 12 percent, compared with the 14 percent success rate of men, but significantly fewer women than men were able to run for office in the ...\n",
      "\n",
      " 7 Topic 7 refugees, asylum, seekers, refugee, unhcr, protection, country\n",
      " - Afghanistan 2013 Section 1. : able to receive visitors on a regular basis. Provisions for alternatives to incarceration were rarely utilized in practice. Regular presidential pardons on holidays were the only practice that diverte ...\n",
      " - Qatar 2014 Section 1. : detainees generally had access to visitors, although prison officials at the state security prison limited access to family and legal counsel. Authorities allowed prisoners and detainees to submit com ...\n",
      "\n",
      " 8 Topic 8 elections, political, parties, election, participation, women\n",
      " - Afghanistan 2013 Section 6. : and Benefits of Disabled Persons provides for equal rights to, and the active participation of, such persons in society. MoLSAMD continued to implement a five-year national action plan through a memor ...\n",
      " - Rwanda 2014 Section 6. : disabilities. Many children with disabilities did not attend primary or secondary school. Although resources were inadequate to train all teachers, the Ministry of Education and UNICEF collaborated to ...\n",
      "\n",
      " 9 Topic 9 hiv, lgbt, discrimination, aids, lgbti, orientation, sexual\n",
      " - Afghanistan 2013 Section 6. : mandatory up to the secondary level (six years for primary school and three years for lower secondary), and the law provides for free education up to and including the college level. Many children, ho ...\n",
      " - Timor-Leste 2014 Section 6. : registration was low. There were no reports of discrimination based on birth registration. While access to services such as schooling do not depend on birth registration, birth registration is necessa ...\n"
     ]
    }
   ],
   "source": [
    "def representative_chunks(df, topic_id, n=3):\n",
    "    sub = df[df[\"topic\"] == topic_id].copy()\n",
    "    if len(sub) == 0:\n",
    "        return []\n",
    "    # choose longer chunks so they contain more meaning\n",
    "    sub[\"n_words\"] = sub[\"text\"].str.split().str.len()\n",
    "    sub = sub.sort_values(\"n_words\", ascending=False).head(20)\n",
    "    return sub.sample(min(n, len(sub)), random_state=42)[[\"year\",\"country\",\"section\",\"text\"]].to_dict(\"records\")\n",
    "\n",
    "for tid in valid_topic_ids[:10]:\n",
    "    print(\"\\n\", tid, topic_name(tid), topic_words_str(topic_model, tid, 10))\n",
    "    reps = representative_chunks(df, tid, n=2)\n",
    "    for r in reps:\n",
    "        print(\" -\", r[\"country\"], r[\"year\"], r[\"section\"], \":\", r[\"text\"][:200], \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Topic validity / interpretability:\n",
    "- The top words match the example texts.\n",
    "2. Cross-country consistency:\n",
    "- Same topics appear in many countries → topics are not random.\n",
    "3. Section alignment:\n",
    "\n",
    "- Many topics match the report structure (e.g., Worker Rights = Section 7, Corruption = Section 4).\n",
    "This is a strong sign the model is working correctly.\n",
    "\n",
    "4. Topic granularity:\n",
    "\n",
    "- Model separates related topics (Topic 3 vs Topic 7: prison conditions vs monitoring)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clear topic names automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_labels = {}\n",
    "for tid in valid_topic_ids[:30]:\n",
    "\n",
    "    words = get_topic_words_clean(topic_model, tid, 5)\n",
    "    topic_labels[tid] = \" / \".join(words[:2]) if len(words) >= 2 else f\"Topic {tid}\"\n",
    "df[\"topic_label_auto\"] = df[\"topic\"].map(topic_labels).fillna(\"outlier\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add “topic → top section”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>section</th>\n",
       "      <th>n</th>\n",
       "      <th>share</th>\n",
       "      <th>top_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Section 7.</td>\n",
       "      <td>4220</td>\n",
       "      <td>0.995283</td>\n",
       "      <td>labor, workers, work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Section 4.</td>\n",
       "      <td>1241</td>\n",
       "      <td>0.976397</td>\n",
       "      <td>prisoners, prison, detention, detainees, autho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>Section 6.</td>\n",
       "      <td>717</td>\n",
       "      <td>0.976839</td>\n",
       "      <td>corruption, public, officials, police</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>Section 1.</td>\n",
       "      <td>615</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>police, torture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>Section 6.</td>\n",
       "      <td>598</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>rape, violence, domestic, women, sexual, victims</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>Section 1.</td>\n",
       "      <td>496</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>freedom, internet, media, press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>Section 3.</td>\n",
       "      <td>376</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>women, children, birth, percent, child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>Section 1.</td>\n",
       "      <td>372</td>\n",
       "      <td>0.986737</td>\n",
       "      <td>refugees, asylum, seekers, refugee, unhcr, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8</td>\n",
       "      <td>Section 6.</td>\n",
       "      <td>350</td>\n",
       "      <td>0.983146</td>\n",
       "      <td>elections, political, parties, election, parti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9</td>\n",
       "      <td>Section 6.</td>\n",
       "      <td>342</td>\n",
       "      <td>0.988439</td>\n",
       "      <td>hiv, lgbt, discrimination, aids, lgbti, orient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10</td>\n",
       "      <td>Section 1.</td>\n",
       "      <td>327</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>disabilities, mental, education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>11</td>\n",
       "      <td>Section 1.</td>\n",
       "      <td>322</td>\n",
       "      <td>0.993827</td>\n",
       "      <td>child, children, age, marriage, years, sexual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>12</td>\n",
       "      <td>Section 3.</td>\n",
       "      <td>317</td>\n",
       "      <td>0.996855</td>\n",
       "      <td>human, international, ngos, ombudsman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>13</td>\n",
       "      <td>Section 2.</td>\n",
       "      <td>276</td>\n",
       "      <td>0.926174</td>\n",
       "      <td>forces, killed, civilians, armed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>14</td>\n",
       "      <td>Section 1.</td>\n",
       "      <td>185</td>\n",
       "      <td>0.790598</td>\n",
       "      <td>problems, human, security, forces, abuses, inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>15</td>\n",
       "      <td>Section 6.</td>\n",
       "      <td>220</td>\n",
       "      <td>0.995475</td>\n",
       "      <td>roma, romani, ethnic, education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>16</td>\n",
       "      <td>Section 1.</td>\n",
       "      <td>218</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>anti, jewish, semitic, holocaust, semitism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>17</td>\n",
       "      <td>Section 6.</td>\n",
       "      <td>218</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>citizenship, stateless, country, bidoon, born,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>18</td>\n",
       "      <td>Section 6.</td>\n",
       "      <td>196</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>idps, displaced, displacement, idp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>19</td>\n",
       "      <td>Section 5.</td>\n",
       "      <td>181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>land, property, restitution, compensation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic     section     n     share  \\\n",
       "2       0  Section 7.  4220  0.995283   \n",
       "7       1  Section 4.  1241  0.976397   \n",
       "10      2  Section 6.   717  0.976839   \n",
       "13      3  Section 1.   615  0.995146   \n",
       "16      4  Section 6.   598  0.996667   \n",
       "18      5  Section 1.   496  0.992000   \n",
       "19      6  Section 3.   376  0.989474   \n",
       "22      7  Section 1.   372  0.986737   \n",
       "25      8  Section 6.   350  0.983146   \n",
       "29      9  Section 6.   342  0.988439   \n",
       "32     10  Section 1.   327  0.990909   \n",
       "34     11  Section 1.   322  0.993827   \n",
       "36     12  Section 3.   317  0.996855   \n",
       "39     13  Section 2.   276  0.926174   \n",
       "43     14  Section 1.   185  0.790598   \n",
       "50     15  Section 6.   220  0.995475   \n",
       "51     16  Section 1.   218  1.000000   \n",
       "52     17  Section 6.   218  1.000000   \n",
       "55     18  Section 6.   196  0.965517   \n",
       "57     19  Section 5.   181  1.000000   \n",
       "\n",
       "                                            top_words  \n",
       "2                                labor, workers, work  \n",
       "7   prisoners, prison, detention, detainees, autho...  \n",
       "10              corruption, public, officials, police  \n",
       "13                                    police, torture  \n",
       "16   rape, violence, domestic, women, sexual, victims  \n",
       "18                    freedom, internet, media, press  \n",
       "19             women, children, birth, percent, child  \n",
       "22  refugees, asylum, seekers, refugee, unhcr, pro...  \n",
       "25  elections, political, parties, election, parti...  \n",
       "29  hiv, lgbt, discrimination, aids, lgbti, orient...  \n",
       "32                    disabilities, mental, education  \n",
       "34      child, children, age, marriage, years, sexual  \n",
       "36              human, international, ngos, ombudsman  \n",
       "39                   forces, killed, civilians, armed  \n",
       "43  problems, human, security, forces, abuses, inc...  \n",
       "50                    roma, romani, ethnic, education  \n",
       "51         anti, jewish, semitic, holocaust, semitism  \n",
       "52  citizenship, stateless, country, bidoon, born,...  \n",
       "55                 idps, displaced, displacement, idp  \n",
       "57          land, property, restitution, compensation  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_section = (df[df[\"topic\"] != -1]\n",
    "               .groupby([\"topic\",\"section\"]).size()\n",
    "               .reset_index(name=\"n\"))\n",
    "top_section[\"share\"] = top_section[\"n\"] / top_section.groupby(\"topic\")[\"n\"].transform(\"sum\")\n",
    "top_section = top_section.sort_values([\"topic\",\"share\"], ascending=[True, False]).groupby(\"topic\").head(1)\n",
    "\n",
    "top_section[\"top_words\"] = top_section[\"topic\"].apply(lambda t: topic_words_str(topic_model, t, 8))\n",
    "top_section.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">To validate topic quality, we examined how topics align with the report structure. For each topic, we identified the section that contains the largest share of its chunks. Most topics show very high concentration (often above 95%) in a single section (e.g., labor rights in Section 7, gender-based violence in Section 6, torture in Section 1). This strong alignment indicates that the topic model captures meaningful themes rather than random word clusters. One topic (security forces abuses) is broader and less concentrated, which is expected for complex themes spanning multiple rights areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Tokens\n",
    "We preserved full text for transformer embeddings to keep context, but removed stopwords when presenting topic keywords and when computing coherence metrics to improve interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_for_coherence(text):\n",
    "#     return [w for w in re.findall(r\"[a-z]+\", text.lower()) if w not in STOP and len(w) >= 3]\n",
    "\n",
    "# tokenized = [tokenize_for_coherence(d) for d in docs_all]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic-by-year comparison for EU and World\n",
    "اینجارو ران کن"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>year</th>\n",
       "      <th>topic</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>delta_first_to_last</th>\n",
       "      <th>topic_name</th>\n",
       "      <th>top_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.176292</td>\n",
       "      <td>0.189891</td>\n",
       "      <td>0.223077</td>\n",
       "      <td>0.046785</td>\n",
       "      <td>Topic 0</td>\n",
       "      <td>l, a, b, o, r, ,,  , w, o, r, k, e, r, s, ,,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>0.044073</td>\n",
       "      <td>0.042350</td>\n",
       "      <td>0.064615</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>Topic 22</td>\n",
       "      <td>k, o, r, e, a, ,,  , d, p, r, k, ,,  , k, i, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.010769</td>\n",
       "      <td>0.009249</td>\n",
       "      <td>Topic 148</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.007748</td>\n",
       "      <td>Topic 75</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.009563</td>\n",
       "      <td>0.016923</td>\n",
       "      <td>0.006285</td>\n",
       "      <td>Topic 16</td>\n",
       "      <td>a, n, t, i, ,,  , j, e, w, i, s, h, ,,  , s, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0.009119</td>\n",
       "      <td>0.013661</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.006266</td>\n",
       "      <td>Topic 11</td>\n",
       "      <td>c, h, i, l, d, ,,  , c, h, i, l, d, r, e, n, ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.010769</td>\n",
       "      <td>0.006210</td>\n",
       "      <td>Topic 57</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>0.033435</td>\n",
       "      <td>0.030055</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.005027</td>\n",
       "      <td>Topic 5</td>\n",
       "      <td>f, r, e, e, d, o, m, ,,  , i, n, t, e, r, n, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34</td>\n",
       "      <td>0.019757</td>\n",
       "      <td>0.020492</td>\n",
       "      <td>0.024615</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>Topic 34</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>0.009119</td>\n",
       "      <td>0.015027</td>\n",
       "      <td>0.013846</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>Topic 15</td>\n",
       "      <td>r, o, m, a, ,,  , r, o, m, a, n, i, ,,  , e, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>Topic 101</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>Topic 128</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>37</td>\n",
       "      <td>0.009119</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.003189</td>\n",
       "      <td>Topic 37</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>27</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.012295</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>Topic 27</td>\n",
       "      <td>h, a, n, ,,  , x, u, a, r, ,,  , m, i, n, o, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>46</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>Topic 46</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "year  topic      2013      2014      2015  delta_first_to_last topic_name  \\\n",
       "0         0  0.176292  0.189891  0.223077             0.046785    Topic 0   \n",
       "1        22  0.044073  0.042350  0.064615             0.020542   Topic 22   \n",
       "2       148  0.001520  0.005464  0.010769             0.009249  Topic 148   \n",
       "3        75  0.004559  0.004098  0.012308             0.007748   Topic 75   \n",
       "4        16  0.010638  0.009563  0.016923             0.006285   Topic 16   \n",
       "5        11  0.009119  0.013661  0.015385             0.006266   Topic 11   \n",
       "6        57  0.004559  0.005464  0.010769             0.006210   Topic 57   \n",
       "7         5  0.033435  0.030055  0.038462             0.005027    Topic 5   \n",
       "8        34  0.019757  0.020492  0.024615             0.004859   Topic 34   \n",
       "9        15  0.009119  0.015027  0.013846             0.004728   Topic 15   \n",
       "10      101  0.001520  0.001366  0.006154             0.004634  Topic 101   \n",
       "11      128  0.000000  0.005464  0.004615             0.004615  Topic 128   \n",
       "12       37  0.009119  0.005464  0.012308             0.003189   Topic 37   \n",
       "13       27  0.004559  0.012295  0.007692             0.003133   Topic 27   \n",
       "14       46  0.004559  0.002732  0.007692             0.003133   Topic 46   \n",
       "\n",
       "year                                          top_words  \n",
       "0     l, a, b, o, r, ,,  , w, o, r, k, e, r, s, ,,  ...  \n",
       "1     k, o, r, e, a, ,,  , d, p, r, k, ,,  , k, i, m...  \n",
       "2                                                        \n",
       "3                                                        \n",
       "4     a, n, t, i, ,,  , j, e, w, i, s, h, ,,  , s, e...  \n",
       "5     c, h, i, l, d, ,,  , c, h, i, l, d, r, e, n, ,...  \n",
       "6                                                        \n",
       "7     f, r, e, e, d, o, m, ,,  , i, n, t, e, r, n, e...  \n",
       "8                                                        \n",
       "9     r, o, m, a, ,,  , r, o, m, a, n, i, ,,  , e, t...  \n",
       "10                                                       \n",
       "11                                                       \n",
       "12                                                       \n",
       "13    h, a, n, ,,  , x, u, a, r, ,,  , m, i, n, o, r...  \n",
       "14                                                       "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def topic_share_by_year(subdf, label):\n",
    "    t = (subdf[subdf[\"topic\"] != -1]\n",
    "         .groupby([\"year\",\"topic\"]).size().reset_index(name=\"n\"))\n",
    "    t[\"share\"] = t[\"n\"] / t.groupby(\"year\")[\"n\"].transform(\"sum\")\n",
    "    t[\"group\"] = label\n",
    "    return t\n",
    "\n",
    "eu_year = topic_share_by_year(df[df[\"is_eu\"]], \"EU\")\n",
    "world_year = topic_share_by_year(df, \"World\")\n",
    "year_cmp = pd.concat([eu_year, world_year], ignore_index=True)\n",
    "\n",
    "# Show top changing topics from first year to last year inside EU\n",
    "pivot = eu_year.pivot_table(index=\"topic\", columns=\"year\", values=\"share\", fill_value=0.0)\n",
    "years = sorted(pivot.columns.tolist())\n",
    "pivot[\"delta_first_to_last\"] = pivot[years[-1]] - pivot[years[0]]\n",
    "out = pivot.sort_values(\"delta_first_to_last\", ascending=False).head(15).copy()\n",
    "out[\"topic_name\"] = out.index.map(topic_name)\n",
    "out[\"top_words\"] = out.index.map(lambda t: \", \".join(topic_words_str(topic_model, int(t), 8)))\n",
    "out.reset_index().rename(columns={\"index\":\"topic\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "topic_to_plot = valid_topic_ids[0]  # choose one important topic\n",
    "tmp = eu_year[eu_year[\"topic\"] == topic_to_plot].sort_values(\"year\")\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(tmp[\"year\"], tmp[\"share\"], marker=\"o\")\n",
    "plt.title(f\"EU topic share over years: {topic_name(topic_to_plot)}\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Share within EU\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country profiles (top topics per country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>topic</th>\n",
       "      <th>n</th>\n",
       "      <th>share</th>\n",
       "      <th>topic_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>Austria</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>Topic 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>Austria</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>Topic 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013</td>\n",
       "      <td>Austria</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>Topic 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>Topic 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>Austria</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>Topic 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2013</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>Topic 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2013</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>Topic 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2013</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>Topic 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2013</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>Topic 44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2013</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>Topic 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2013</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>Topic 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2013</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>Topic 18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2013</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>Topic 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2013</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>Topic 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2013</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>Topic 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2013</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Topic 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2013</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Topic 18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2013</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>Topic 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2013</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>Topic 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2013</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>Topic 76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year   country  topic  n     share topic_name\n",
       "0   2013   Austria      0  3  0.142857    Topic 0\n",
       "1   2013   Austria      1  2  0.095238    Topic 1\n",
       "10  2013   Austria     22  2  0.095238   Topic 22\n",
       "2   2013   Austria      2  1  0.047619    Topic 2\n",
       "3   2013   Austria      4  1  0.047619    Topic 4\n",
       "17  2013   Belgium      0  4  0.153846    Topic 0\n",
       "20  2013   Belgium      3  2  0.076923    Topic 3\n",
       "27  2013   Belgium     22  2  0.076923   Topic 22\n",
       "31  2013   Belgium     44  2  0.076923   Topic 44\n",
       "18  2013   Belgium      1  1  0.038462    Topic 1\n",
       "37  2013  Bulgaria      0  6  0.193548    Topic 0\n",
       "51  2013  Bulgaria     18  3  0.096774   Topic 18\n",
       "38  2013  Bulgaria      1  2  0.064516    Topic 1\n",
       "41  2013  Bulgaria      4  2  0.064516    Topic 4\n",
       "44  2013  Bulgaria      8  2  0.064516    Topic 8\n",
       "58  2013   Croatia      0  6  0.200000    Topic 0\n",
       "66  2013   Croatia     18  3  0.100000   Topic 18\n",
       "59  2013   Croatia      1  2  0.066667    Topic 1\n",
       "60  2013   Croatia      2  2  0.066667    Topic 2\n",
       "72  2013   Croatia     76  2  0.066667   Topic 76"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_topic = (\n",
    "    df[(df[\"is_eu\"]) & (df[\"topic\"] != -1)]\n",
    "    .groupby([\"year\",\"country\",\"topic\"]).size().reset_index(name=\"n\")\n",
    ")\n",
    "country_topic[\"share\"] = country_topic[\"n\"] / country_topic.groupby([\"year\",\"country\"])[\"n\"].transform(\"sum\")\n",
    "country_topic[\"topic_name\"] = country_topic[\"topic\"].apply(topic_name)\n",
    "\n",
    "top5 = (country_topic.sort_values([\"year\",\"country\",\"share\"], ascending=[True, True, False])\n",
    "        .groupby([\"year\",\"country\"]).head(5))\n",
    "top5.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section analysis (Executive Summary vs Section 1…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>topic</th>\n",
       "      <th>n</th>\n",
       "      <th>share_in_section</th>\n",
       "      <th>topic_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EXECUTIVE SUMMARY</td>\n",
       "      <td>45</td>\n",
       "      <td>82</td>\n",
       "      <td>0.147217</td>\n",
       "      <td>Topic 45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EXECUTIVE SUMMARY</td>\n",
       "      <td>53</td>\n",
       "      <td>69</td>\n",
       "      <td>0.123878</td>\n",
       "      <td>Topic 53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>EXECUTIVE SUMMARY</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "      <td>0.100539</td>\n",
       "      <td>Topic 65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>EXECUTIVE SUMMARY</td>\n",
       "      <td>70</td>\n",
       "      <td>49</td>\n",
       "      <td>0.087971</td>\n",
       "      <td>Topic 70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>EXECUTIVE SUMMARY</td>\n",
       "      <td>87</td>\n",
       "      <td>38</td>\n",
       "      <td>0.068223</td>\n",
       "      <td>Topic 87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Section 1.</td>\n",
       "      <td>3</td>\n",
       "      <td>615</td>\n",
       "      <td>0.133899</td>\n",
       "      <td>Topic 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Section 1.</td>\n",
       "      <td>5</td>\n",
       "      <td>496</td>\n",
       "      <td>0.107990</td>\n",
       "      <td>Topic 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Section 1.</td>\n",
       "      <td>7</td>\n",
       "      <td>372</td>\n",
       "      <td>0.080993</td>\n",
       "      <td>Topic 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Section 1.</td>\n",
       "      <td>10</td>\n",
       "      <td>327</td>\n",
       "      <td>0.071195</td>\n",
       "      <td>Topic 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Section 1.</td>\n",
       "      <td>11</td>\n",
       "      <td>322</td>\n",
       "      <td>0.070107</td>\n",
       "      <td>Topic 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Section 2.</td>\n",
       "      <td>13</td>\n",
       "      <td>276</td>\n",
       "      <td>0.112195</td>\n",
       "      <td>Topic 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Section 2.</td>\n",
       "      <td>22</td>\n",
       "      <td>169</td>\n",
       "      <td>0.068699</td>\n",
       "      <td>Topic 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Section 2.</td>\n",
       "      <td>26</td>\n",
       "      <td>123</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>Topic 26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Section 2.</td>\n",
       "      <td>25</td>\n",
       "      <td>118</td>\n",
       "      <td>0.047967</td>\n",
       "      <td>Topic 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Section 2.</td>\n",
       "      <td>29</td>\n",
       "      <td>116</td>\n",
       "      <td>0.047154</td>\n",
       "      <td>Topic 29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Section 3.</td>\n",
       "      <td>6</td>\n",
       "      <td>376</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>Topic 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Section 3.</td>\n",
       "      <td>12</td>\n",
       "      <td>317</td>\n",
       "      <td>0.396250</td>\n",
       "      <td>Topic 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Section 3.</td>\n",
       "      <td>111</td>\n",
       "      <td>18</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>Topic 111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Section 3.</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>Topic 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Section 3.</td>\n",
       "      <td>88</td>\n",
       "      <td>12</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>Topic 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Section 4.</td>\n",
       "      <td>1</td>\n",
       "      <td>1241</td>\n",
       "      <td>0.985703</td>\n",
       "      <td>Topic 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Section 4.</td>\n",
       "      <td>163</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003177</td>\n",
       "      <td>Topic 163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Section 4.</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>Topic 56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Section 4.</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>Topic 93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Section 4.</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>Topic 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Section 5.</td>\n",
       "      <td>19</td>\n",
       "      <td>181</td>\n",
       "      <td>0.364185</td>\n",
       "      <td>Topic 19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>Section 5.</td>\n",
       "      <td>20</td>\n",
       "      <td>173</td>\n",
       "      <td>0.348089</td>\n",
       "      <td>Topic 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Section 5.</td>\n",
       "      <td>69</td>\n",
       "      <td>51</td>\n",
       "      <td>0.102616</td>\n",
       "      <td>Topic 69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Section 5.</td>\n",
       "      <td>73</td>\n",
       "      <td>47</td>\n",
       "      <td>0.094567</td>\n",
       "      <td>Topic 73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Section 5.</td>\n",
       "      <td>128</td>\n",
       "      <td>19</td>\n",
       "      <td>0.038229</td>\n",
       "      <td>Topic 128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Section 6.</td>\n",
       "      <td>2</td>\n",
       "      <td>717</td>\n",
       "      <td>0.147258</td>\n",
       "      <td>Topic 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Section 6.</td>\n",
       "      <td>4</td>\n",
       "      <td>598</td>\n",
       "      <td>0.122818</td>\n",
       "      <td>Topic 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Section 6.</td>\n",
       "      <td>8</td>\n",
       "      <td>350</td>\n",
       "      <td>0.071883</td>\n",
       "      <td>Topic 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Section 6.</td>\n",
       "      <td>9</td>\n",
       "      <td>342</td>\n",
       "      <td>0.070240</td>\n",
       "      <td>Topic 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Section 6.</td>\n",
       "      <td>15</td>\n",
       "      <td>220</td>\n",
       "      <td>0.045184</td>\n",
       "      <td>Topic 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Section 7.</td>\n",
       "      <td>0</td>\n",
       "      <td>4220</td>\n",
       "      <td>0.990610</td>\n",
       "      <td>Topic 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Section 7.</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>Topic 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Section 7.</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>Topic 51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>Section 7.</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>Topic 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Section 7.</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>Topic 14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               section  topic     n  share_in_section topic_name\n",
       "14   EXECUTIVE SUMMARY     45    82          0.147217   Topic 45\n",
       "15   EXECUTIVE SUMMARY     53    69          0.123878   Topic 53\n",
       "21   EXECUTIVE SUMMARY     65    56          0.100539   Topic 65\n",
       "22   EXECUTIVE SUMMARY     70    49          0.087971   Topic 70\n",
       "26   EXECUTIVE SUMMARY     87    38          0.068223   Topic 87\n",
       "51          Section 1.      3   615          0.133899    Topic 3\n",
       "53          Section 1.      5   496          0.107990    Topic 5\n",
       "54          Section 1.      7   372          0.080993    Topic 7\n",
       "55          Section 1.     10   327          0.071195   Topic 10\n",
       "56          Section 1.     11   322          0.070107   Topic 11\n",
       "150         Section 2.     13   276          0.112195   Topic 13\n",
       "154         Section 2.     22   169          0.068699   Topic 22\n",
       "156         Section 2.     26   123          0.050000   Topic 26\n",
       "155         Section 2.     25   118          0.047967   Topic 25\n",
       "157         Section 2.     29   116          0.047154   Topic 29\n",
       "228         Section 3.      6   376          0.470000    Topic 6\n",
       "229         Section 3.     12   317          0.396250   Topic 12\n",
       "240         Section 3.    111    18          0.022500  Topic 111\n",
       "230         Section 3.     13    16          0.020000   Topic 13\n",
       "237         Section 3.     88    12          0.015000   Topic 88\n",
       "249         Section 4.      1  1241          0.985703    Topic 1\n",
       "259         Section 4.    163     4          0.003177  Topic 163\n",
       "252         Section 4.     56     3          0.002383   Topic 56\n",
       "254         Section 4.     93     3          0.002383   Topic 93\n",
       "250         Section 4.     14     2          0.001589   Topic 14\n",
       "265         Section 5.     19   181          0.364185   Topic 19\n",
       "266         Section 5.     20   173          0.348089   Topic 20\n",
       "269         Section 5.     69    51          0.102616   Topic 69\n",
       "270         Section 5.     73    47          0.094567   Topic 73\n",
       "276         Section 5.    128    19          0.038229  Topic 128\n",
       "279         Section 6.      2   717          0.147258    Topic 2\n",
       "280         Section 6.      4   598          0.122818    Topic 4\n",
       "282         Section 6.      8   350          0.071883    Topic 8\n",
       "283         Section 6.      9   342          0.070240    Topic 9\n",
       "285         Section 6.     15   220          0.045184   Topic 15\n",
       "357         Section 7.      0  4220          0.990610    Topic 0\n",
       "358         Section 7.      2     8          0.001878    Topic 2\n",
       "369         Section 7.     51     4          0.000939   Topic 51\n",
       "360         Section 7.      8     3          0.000704    Topic 8\n",
       "363         Section 7.     14     3          0.000704   Topic 14"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_topic = (\n",
    "    df[(df[\"topic\"] != -1)]\n",
    "    .groupby([\"section\",\"topic\"]).size().reset_index(name=\"n\")\n",
    ")\n",
    "sec_topic[\"share_in_section\"] = sec_topic[\"n\"] / sec_topic.groupby(\"section\")[\"n\"].transform(\"sum\")\n",
    "sec_topic[\"topic_name\"] = sec_topic[\"topic\"].apply(topic_name)\n",
    "\n",
    "sec_topic.sort_values([\"section\",\"share_in_section\"], ascending=[True, False]).groupby(\"section\").head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model (NMF) to compare with BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bertopic_coh': 0.691497653731012,\n",
       " 'nmf_coh': 0.6690818455565415,\n",
       " 'bertopic_div10': 0.5197860962566845,\n",
       " 'nmf_div10': 0.84}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Use same docs_all you used for BERTopic\n",
    "vectorizer = TfidfVectorizer(max_df=0.95, min_df=5, stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(docs_all)\n",
    "\n",
    "n_topics = min(20, len(valid_topic_ids))  # choose 15-30 usually; keep small for report\n",
    "nmf = NMF(n_components=n_topics, random_state=42)\n",
    "W = nmf.fit_transform(X)\n",
    "H = nmf.components_\n",
    "vocab = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "def nmf_top_words(H, vocab, topn=15):\n",
    "    topics = []\n",
    "    for k in range(H.shape[0]):\n",
    "        top = vocab[np.argsort(H[k])][::-1][:topn].tolist()\n",
    "        topics.append(top)\n",
    "    return topics\n",
    "\n",
    "nmf_words = nmf_top_words(H, vocab, topn=20)\n",
    "\n",
    "# Compare coherence/diversity with your existing functions\n",
    "nmf_div10 = topic_diversity(nmf_words, topk=10)\n",
    "nmf_coh = coherence_cv([d.split() for d in docs_all], nmf_words)\n",
    "\n",
    "{\"bertopic_coh\": metrics[\"coherence_c_v\"], \"nmf_coh\": nmf_coh,\n",
    " \"bertopic_div10\": metrics[\"topic_diversity_top10\"], \"nmf_div10\": nmf_div10}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change over time inside EU (2014 → 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_df = df[df[\"is_eu\"] & (df[\"topic\"] != -1)].copy()\n",
    "\n",
    "year_topic = (eu_df.groupby([\"year\", \"topic\"]).size().reset_index(name=\"n\"))\n",
    "year_topic[\"share_within_year\"] = year_topic[\"n\"] / year_topic.groupby(\"year\")[\"n\"].transform(\"sum\")\n",
    "\n",
    "pivot = year_topic.pivot_table(index=\"topic\", columns=\"year\", values=\"share_within_year\", fill_value=0.0)\n",
    "if len(pivot.columns) >= 2:\n",
    "    years = sorted(pivot.columns.tolist())\n",
    "    pivot[\"delta\"] = pivot[years[-1]] - pivot[years[0]]\n",
    "    out = pivot.sort_values(\"delta\", ascending=False).head(15).copy()\n",
    "    out[\"top_words\"] = out.index.map(lambda t: \", \".join(get_topic_words(topic_model, int(t), 8)))\n",
    "    out.reset_index()\n",
    "else:\n",
    "    print(\"Need both years present to compute change.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot labels on EU chunks (sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m      5\u001b[39m LABELS = [\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcorruption\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mjudicial independence\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlabor rights\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     19\u001b[39m ]\n\u001b[32m     21\u001b[39m zs = eu_df.sample(\u001b[38;5;28mmin\u001b[39m(\u001b[32m400\u001b[39m, \u001b[38;5;28mlen\u001b[39m(eu_df)), random_state=\u001b[32m7\u001b[39m).copy()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m res = \u001b[43mzshot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLABELS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_label\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m top3 = []\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m res:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/transformers/pipelines/zero_shot_classification.py:209\u001b[39m, in \u001b[36mZeroShotClassificationPipeline.__call__\u001b[39m\u001b[34m(self, sequences, *args, **kwargs)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnable to understand extra arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/transformers/pipelines/base.py:1448\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1444\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[32m   1445\u001b[39m     final_iterator = \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   1446\u001b[39m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[32m   1447\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m     outputs = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[32m   1450\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:126\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_item()\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m item = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterator)\n\u001b[32m    127\u001b[39m processed = \u001b[38;5;28mself\u001b[39m.infer(item, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:271\u001b[39m, in \u001b[36mPipelinePackIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    268\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m     processed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    273\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch.Tensor):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/transformers/pipelines/base.py:1374\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1372\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1373\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1374\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1375\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/transformers/pipelines/zero_shot_classification.py:232\u001b[39m, in \u001b[36mZeroShotClassificationPipeline._forward\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect.signature(model_forward).parameters:\n\u001b[32m    231\u001b[39m     model_inputs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m model_outputs = {\n\u001b[32m    235\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcandidate_label\u001b[39m\u001b[33m\"\u001b[39m: candidate_label,\n\u001b[32m    236\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msequence\u001b[39m\u001b[33m\"\u001b[39m: sequence,\n\u001b[32m    237\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mis_last\u001b[39m\u001b[33m\"\u001b[39m: inputs[\u001b[33m\"\u001b[39m\u001b[33mis_last\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    238\u001b[39m     **outputs,\n\u001b[32m    239\u001b[39m }\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1603\u001b[39m, in \u001b[36mBartForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1598\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1599\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m   1600\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPassing input embeddings is currently not supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1601\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1603\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1604\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1605\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1606\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1607\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1608\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1610\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1611\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1612\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1613\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1614\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1615\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1620\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# last hidden state\u001b[39;00m\n\u001b[32m   1622\u001b[39m eos_mask = input_ids.eq(\u001b[38;5;28mself\u001b[39m.config.eos_token_id).to(hidden_states.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1289\u001b[39m, in \u001b[36mBartModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1282\u001b[39m     encoder_outputs = BaseModelOutput(\n\u001b[32m   1283\u001b[39m         last_hidden_state=encoder_outputs[\u001b[32m0\u001b[39m],\n\u001b[32m   1284\u001b[39m         hidden_states=encoder_outputs[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1285\u001b[39m         attentions=encoder_outputs[\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1286\u001b[39m     )\n\u001b[32m   1288\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_values, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1289\u001b[39m decoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1290\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1291\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1292\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1293\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1294\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1303\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs + encoder_outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1083\u001b[39m, in \u001b[36mBartDecoder.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1071\u001b[39m self_attn_cache = (\n\u001b[32m   1072\u001b[39m     past_key_values.self_attention_cache\n\u001b[32m   1073\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(past_key_values, EncoderDecoderCache)\n\u001b[32m   1074\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m past_key_values\n\u001b[32m   1075\u001b[39m )\n\u001b[32m   1077\u001b[39m attention_mask = \u001b[38;5;28mself\u001b[39m._update_causal_mask(\n\u001b[32m   1078\u001b[39m     attention_mask,\n\u001b[32m   1079\u001b[39m     inputs_embeds,\n\u001b[32m   1080\u001b[39m     cache_position,\n\u001b[32m   1081\u001b[39m     self_attn_cache,\n\u001b[32m   1082\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1083\u001b[39m encoder_attention_mask = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_cross_attn_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1085\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1087\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[38;5;66;03m# embed positions\u001b[39;00m\n\u001b[32m   1091\u001b[39m positions = \u001b[38;5;28mself\u001b[39m.embed_positions(\u001b[38;5;28minput\u001b[39m, past_key_values_length, position_ids=cache_position)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:681\u001b[39m, in \u001b[36mBartPreTrainedModel._update_cross_attn_mask\u001b[39m\u001b[34m(self, encoder_hidden_states, encoder_attention_mask, input_shape, inputs_embeds)\u001b[39m\n\u001b[32m    675\u001b[39m             causal_mask[:, :, :, :mask_length] = causal_mask[:, :, :, :mask_length].masked_fill(\n\u001b[32m    676\u001b[39m                 padding_mask, min_dtype\n\u001b[32m    677\u001b[39m             )\n\u001b[32m    679\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m causal_mask\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_cross_attn_mask\u001b[39m(\n\u001b[32m    682\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    683\u001b[39m     encoder_hidden_states: Union[torch.Tensor, \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[32m    684\u001b[39m     encoder_attention_mask: Union[torch.Tensor, \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[32m    685\u001b[39m     input_shape: torch.Size,\n\u001b[32m    686\u001b[39m     inputs_embeds: torch.Tensor,\n\u001b[32m    687\u001b[39m ):\n\u001b[32m    688\u001b[39m     \u001b[38;5;66;03m# expand encoder attention mask\u001b[39;00m\n\u001b[32m    689\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m encoder_attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    690\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config._attn_implementation == \u001b[33m\"\u001b[39m\u001b[33mflash_attention_2\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "zshot = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "LABELS = [\n",
    "    \"corruption\",\n",
    "    \"judicial independence\",\n",
    "    \"police abuse\",\n",
    "    \"prison conditions\",\n",
    "    \"freedom of expression\",\n",
    "    \"freedom of assembly\",\n",
    "    \"religious freedom\",\n",
    "    \"refugees and asylum\",\n",
    "    \"human trafficking\",\n",
    "    \"anti-Semitism\",\n",
    "    \"LGBTQ+ rights\",\n",
    "    \"women's rights\",\n",
    "    \"labor rights\"\n",
    "]\n",
    "\n",
    "zs = eu_df.sample(min(400, len(eu_df)), random_state=7).copy()\n",
    "res = zshot(zs[\"text\"].tolist(), candidate_labels=LABELS, multi_label=True)\n",
    "\n",
    "top3 = []\n",
    "for r in res:\n",
    "    pairs = sorted(zip(r[\"labels\"], r[\"scores\"]), key=lambda x: x[1], reverse=True)[:3]\n",
    "    top3.append([p[0] for p in pairs])\n",
    "\n",
    "zs[\"top3_labels\"] = top3\n",
    "labels_by_topic = (zs[[\"topic\",\"top3_labels\"]].explode(\"top3_labels\")\n",
    "                   .groupby([\"topic\",\"top3_labels\"]).size()\n",
    "                   .reset_index(name=\"count\")\n",
    "                   .sort_values([\"topic\",\"count\"], ascending=[True, False]))\n",
    "labels_by_topic.head(20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
